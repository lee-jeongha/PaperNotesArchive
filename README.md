# Paper Notes Archive

## Brief Notes
- **USENIX FAST 2023** <sup>[#B01](./paper_notes/B01_USENIX_FAST_2023/)</sup><sub>&nbsp;2023.06-2023.07</sub>
  > A collection of brief, topic-focused notes on FAST '23 papers for a quick read. <br/>
  > FAST, 2023

## Paper Notes
- **SecretFlow-SPU** <sup>[#01](./paper_notes/01_SecretFlow-SPU/SecretFlow-SPU.pdf)</sup><sub>&nbsp;2023.08.03</sub>
  > ATC, 2023

- **Cyclosa** <sup>[#02](./paper_notes/02_Cyclosa/Cyclosa.pdf)</sup><sub>&nbsp;2023.08.04</sub>
  > GraphSearch
  > ATC, 2023

- **SHADE: Enable Fundamental Cacheability for Distributed Deep Learning Training** <sup>[#03](./paper_notes/03_SHADE/SHADE.pdf)</sup><sub>&nbsp;2023.08.07</sub>
  > DeepLearning, FileI/O <br/>
  > FAST, 2023

- **Not All Samples Are Created Equal: Deep Learning with Importance Sampling** <sup>[#04](./paper_notes/04_Not_all_samples_are_created_equal/Not_all_samples_are_created_equal.pdf)</sup><sub>&nbsp;2023.08.21</sub>
  > DeepLearning, FileI/O <br/>
  > ICML, 2018

- **Clairvoyant Prefetching for Distributed Machine Learning I/O** <sup>[#05](./paper_notes/05_NoPFS/NoPFS.pdf)</sup><sub>&nbsp;2023.11.07</sub>
  > `NoPFS` <br/>
  > DeepLearning, Distributed, FileI/O <br/>
  > SC, 2021

- **Accelerating Data Loading in Deep Neural Network Training** <sup>[#06](./paper_notes/06_Accelerating_data_loading_in_DNN_training/Accelerating_data_loading_in_DNN_training.pdf)</sup><sub>&nbsp;2023.11.07</sub>
  > DeepLearning, Distributed, FileI/O <br/>
  > HiPC, 2019

- **Why Globally Re-shuffle? Revisiting Data Shuffling in Large Scale Deep Learning** <sup>[#07](./paper_notes/07_Why_globally_re-shuffle/Why_globally_re-shuffle.pdf)</sup><sub>&nbsp;2023.11.08</sub>
  > DeepLearning, Distributed, FileI/O <br/>
  > IPDPS, 2022

- **Entropy-Aware I/O Pipelining for Large-Scale Deep Learning on HPC Systems** <sup>[#08](./paper_notes/08_DeepIO/DeepIO.pdf)</sup><sub>&nbsp;2023.11.08</sub>
  > `DeepIO` <br/>
  > DeepLearning, Distributed, FileI/O <br/>
  > MASCOTS, 2018

- **Refurbish Your Training Data: Reusing Partially Augmented Samples for Faster Deep Neural Network Training** <sup>[#09](./paper_notes/09_Revamper/Revamper.pdf)</sup><sub>&nbsp;2023.11.21</sub>
  > `Revamper` <br/>
  > DeepLearning, FileI/O <br/>
  > ATC, 2021

- **Training Deep Models Faster with Robust, Approximate Importance Sampling** <sup>[#10](./paper_notes/10_RAIS/RAIS.pdf)</sup><sub>&nbsp;2023.11.22</sub>
  > `RAIS` <br/>
  > DeepLearning, FileI/O <br/>
  > NIPS, 2018

- **Are You Killing Time? Predicting Smartphone Users' Time-killing Moments via Fusion of Smartphone Sensor Data and Screenshots** <sup>[#11](./paper_notes/11_Are_you_killing_time/Are_you_killing_time.pdf)</sup><sub>&nbsp;2023.12.04</sub>
  > Mobile <br/>
  > CHI, 2023

- **Early-Adaptor: An Adaptive Framework for Proactive UVM Memory Management** <sup>[#12](./paper_notes/12_Early-Adaptor/Early-Adaptor.pdf)</sup><sub>&nbsp;2023.12.09</sub>
  > UnifiedMemory <br/>
  > ISPASS, 2023

- **Batch-Aware Unified Memory Management in GPUs for Irregular Workloads** <sup>[#13](./paper_notes/13_Batch-Aware_unified_memory_management_in_GPUs_for_irregular_workloads/Batch-Aware_unified_memory_management_in_GPUs_for_irregular_workloads.pdf)</sup><sub>&nbsp;2023.12.26</sub>
  > GraphSearch, UnifiedMemory <br/>
  > ASPLOS, 2020

- **Adaptive Page Migration for Irregular Data-intensive Applications under GPU Memory Oversubscription** <sup>[#14](./paper_notes/14_Adaptive_page_migration_for_irregular_data-intensive_applications_under_GPU_memory_oversubscription/Adaptive_page_migration_for_irregular_data-intensive_applications_under_GPU_memory_oversubscription.pdf)</sup><sub>&nbsp;2024.01.08</sub>
  > UnifiedMemory <br/>
  > IPDPS, 2020

- **Faster Neural Network Training with Data Echoing** <sup>[#15](./paper_notes/15_Faster_NN_training_with_data_echoing/Faster_NN_training_with_data_echoing.pdf)</sup><sub>&nbsp;2024.02.08</sub>
  > DeepLearning, FileI/O <br/>
  > 2019

- **Computational Storage for an Energy-Efficient Deep Neural Network Training System** <sup>[#16](./paper_notes/16_Computational_storage_for_an_energy-efficient_DNN_training_system/Computational_storage_for_an_energy-efficient_DNN_training_system.pdf)</sup><sub>&nbsp;2024.03.03</sub>
  > ComputationalStorage, DeepLearning, NonVolatileMemory <br/>
  > Euro-Par, 2023

- **FlashNeuron: SSD-Enabled Large-Batch Training of Very Deep Neural Networks** <sup>[#17](./paper_notes/17_FlashNeuron/FlashNeuron.pdf)</sup><sub>&nbsp;2024.03.13</sub>
  > FAST, 2021

- **Î»-IO: A Unified IO Stack for Computational Storage** <sup>[#18](./paper_notes/18_LambdaIO/LambdaIO.pdf)</sup><sub>&nbsp;2024.03.14</sub>
  > ComputationalStorage, FileI/O <br/>
  > FAST, 2023

- **A Fast and Flexible Hardware-based Virtualization Mechanism for Computational Storage Devices** <sup>[#19](./paper_notes/19_Fast_and_flexible_HW-based_virtualization_mechanism_for_computational_storage_devices/Fast_and_flexible_HW-based_virtualization_mechanism_for_computational_storage_devices.pdf)</sup><sub>&nbsp;2024.03.15</sub>
  > ComputationalStorage <br/>
  > ATC, 2021

- **Deep Active Learning for Image Classification** <sup>[#20](./paper_notes/20_Deep_active_learning/Deep_active_learning.pdf)</sup><sub>&nbsp;2024.06.21</sub>
  > DeepLearning, FileI/O <br/>
  > ICIP, 2017

- **Deep Bayesian active learning with image data** <sup>[#21](./paper_notes/21_Deep_bayesian_active_learning/Deep_bayesian_active_learning.pdf)</sup><sub>&nbsp;2024.08.17</sub>
  > DeepLearning, FileI/O <br/>
  > ICML, 2017

- **Memory Harvesting in Multi-GPU Systems with Hierarchical Unified Virtual Memory** <sup>[#22](./paper_notes/22_HUVM/HUVM.pdf)</sup><sub>&nbsp;2024.10.14</sub>
  > `HUVM` <br/>
  > UnifiedMemory <br/>
  > ATC, 2022

- **CSOT: Curriculum and Structure-Aware Optimal Transport for Learning with Noisy Labels** <sup>[#23](./paper_notes/23_CSOT/CSOT.pdf)</sup><sub>&nbsp;2025.08.17</sub>
  > DeepLearning <br/>
  > NIPS, 2023
